{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "from bson.son import SON\n",
    "import pprint\n",
    "from pymongo import MongoClient\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "\n",
    "import avg_age\n",
    "import top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mysql_engine():\n",
    "    engine = create_engine('mysql+pymysql://imdb:imdb@localhost:3306/imdb')\n",
    "    return engine\n",
    "\n",
    "def get_spark():\n",
    "    conf = SparkConf().setAppName('jupyter').setMaster('spark://0.0.0.0:7077')\\\n",
    "            .set('spark.jars.packages', 'mysql:mysql-connector-java:8.0.15,org.mongodb.spark:mongo-spark-connector_2.11:2.4.0')\\\n",
    "            .set('spark.executor.memory', '4g')\n",
    "    \n",
    "    spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "        \n",
    "    return spark\n",
    "\n",
    "# Init Spark\n",
    "spark = get_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init MySQL\n",
    "engine = mysql_engine()\n",
    "\n",
    "url = \"jdbc:mysql://localhost:3306/imdb\"\n",
    "properties = {'driver': 'com.mysql.jdbc.Driver', \n",
    "                'user': \"imdb\",\n",
    "                'password': \"imdb\"}\n",
    "\n",
    "name_basics = spark.read.jdbc(url=url, table=\"name_basics\", properties=properties)\n",
    "title_basics = spark.read.jdbc(url=url, table=\"title_basics\", properties=properties)\n",
    "title_principals = spark.read.jdbc(url=url, table=\"title_principals\", properties=properties)\n",
    "title_ratings = spark.read.jdbc(url=url, table=\"title_ratings\", properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Mongo\n",
    "mongo_client = MongoClient('mongodb://localhost:27017/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avg age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"python mysql\")\n",
    "%timeit -n 1 -r 1 avg_age.py_mysql(engine)\n",
    "\n",
    "print(\"spark mysql\")\n",
    "%timeit -n 1 -r 1 avg_age.spark_mysql(name_basics, title_basics, title_principals)\n",
    "\n",
    "py_mongo(mongo_client, avg_age.pipeline)\n",
    "\n",
    "spark_mongo(spark, avg_age.pipeline).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_10_py_mysql(engine):\n",
    "    \n",
    "    query = \"\"\"\n",
    "       SELECT * FROM (\n",
    "            SELECT\n",
    "                ROW_NUMBER() OVER (PARTITION BY titles.titleType, titles.startYear ORDER BY averageRating DESC) AS row_num,\n",
    "                originalTitle,\n",
    "                titleType,\n",
    "                startYear, \n",
    "                averageRating\n",
    "            FROM\n",
    "                title_basics titles\n",
    "                    JOIN\n",
    "                title_ratings ratings ON titles.tconst = ratings.tconst\n",
    "            WHERE startYear IS NOT NULL\n",
    "        ) AS ranking\n",
    "        WHERE ranking.row_num <= 10\n",
    "        ORDER BY titleType, startYear, averageRating DESC;\n",
    "    \"\"\"\n",
    "    stmt = text(query)\n",
    "    \n",
    "    conn = engine.connect()\n",
    "    \n",
    "    rs = conn.execute(stmt)\n",
    "    \n",
    "    rs.fetchall()\n",
    "    \n",
    "    conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.26 s ± 14.1 ms per loop (mean ± std. dev. of 2 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "top_10_py_mysql(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_mysql(title_basics, title_ratings):\n",
    "    \n",
    "    titles = title_basics.select('tconst', 'startYear', 'originalTitle', 'titleType')\n",
    "    titles = titles.withColumn('startYear', titles['startYear'].cast(IntegerType()))\\\n",
    "                    .where(titles['startYear'].isNotNull())\n",
    "    \n",
    "    ratings = title_ratings.select('tconst', 'averageRating')\n",
    "    \n",
    "    result = ratings.join(titles, on=['tconst'])\n",
    "    \n",
    "    window = Window.partitionBy(['titleType', 'startYear']).orderBy(desc('averageRating'))\n",
    "\n",
    "    result = result.select('*', rank().over(window).alias('rank')).filter(col('rank') <= 10)\n",
    "    \n",
    "    result = result.orderBy('titleType', 'startYear', desc('averageRating'))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 s ± 814 ms per loop (mean ± std. dev. of 2 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3 -r 2\n",
    "\n",
    "spark_mysql(title_basics, title_ratings).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "        { \"$match\": {\"startYear\": {\"$ne\": '\\\\N'} } },\n",
    "        { \"$match\": {\"startYear\": 2017 } },\n",
    "        { \"$match\": {\"titleType\": 'tvEpisode' } },\n",
    "        { \"$match\": {\"averageRating\": {'$exists': 'true'} } },\n",
    "        { \"$sort\": {'averageRating': -1} },\n",
    "        { '$limit': 10},\n",
    "        { \"$project\": {\n",
    "            \"_id\": 0,\n",
    "            'titleType': 1,\n",
    "            'startYear': 1,\n",
    "            'originalTitle': 1,\n",
    "            'averageRating': 1\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def py_mongo(mongo_client, pipeline):\n",
    "    db = mongo_client['imdb']\n",
    "    \n",
    "    db.titles.aggregate(pipeline)\n",
    "    #pprint.pprint(db.command('aggregate', 'titles', pipeline=pipeline, explain=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.95 s ± 1.86 ms per loop (mean ± std. dev. of 2 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3 -r 2\n",
    "\n",
    "py_mongo(mongo_client, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_mongo(spark, pipeline):\n",
    "    \n",
    "    df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    "            .option(\"uri\", \"mongodb://localhost:27017/imdb.titles\") \\\n",
    "            .option(\"pipeline\", pipeline) \\\n",
    "            .load()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.4 s ± 58.2 ms per loop (mean ± std. dev. of 2 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3 -r 2\n",
    "\n",
    "spark_mongo(spark, pipeline).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
